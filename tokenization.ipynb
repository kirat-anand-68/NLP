{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72240216",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"Hello welcome,to kirat singh anand nlp  projects.\n",
    "please learn it in the correct way .\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fafc797d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello welcome,to kirat singh anand nlp  projects.\\nplease learn it in the correct way .\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61daaeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### tolenozation-> conver the sentence in to the paragraph\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bff531ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "documnets=sent_tokenize(corpus)\n",
    "#form the fullstop and the comma it make the new sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3bae4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documnets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d983e8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello welcome,to kirat singh anand nlp  projects.\n",
      "please learn it in the correct way .\n"
     ]
    }
   ],
   "source": [
    "for sentence in documnets:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a215e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## word tokenization\n",
    "## conevrt a paragraph nto words and the sentenec into the words'ArithmeticError\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3d37ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'kirat',\n",
       " 'singh',\n",
       " 'anand',\n",
       " 'nlp',\n",
       " 'projects',\n",
       " '.',\n",
       " 'please',\n",
       " 'learn',\n",
       " 'it',\n",
       " 'in',\n",
       " 'the',\n",
       " 'correct',\n",
       " 'way',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "990dcbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76f1e04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'kirat',\n",
       " 'singh',\n",
       " 'anand',\n",
       " 'nlp',\n",
       " 'projects',\n",
       " '.',\n",
       " 'please',\n",
       " 'learn',\n",
       " 'it',\n",
       " 'in',\n",
       " 'the',\n",
       " 'correct',\n",
       " 'way',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9720a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d90b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ba58fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'kirat',\n",
       " 'singh',\n",
       " 'anand',\n",
       " 'nlp',\n",
       " 'projects.',\n",
       " 'please',\n",
       " 'learn',\n",
       " 'it',\n",
       " 'in',\n",
       " 'the',\n",
       " 'correct',\n",
       " 'way',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(corpus)\n",
    "## full stop is not treated as the separate word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91ec443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEMMING-> reducing the word to its root word\n",
    "## let i solving a classification problem and i have the words\n",
    "## liked liking likes like\n",
    "## reviews -----> eating,eat,eaten\n",
    "\n",
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"programmed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afda2527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# porter stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "stemming=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eacfb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original word:eating----->stemmed word:eat\n",
      "original word:eats----->stemmed word:eat\n",
      "original word:eaten----->stemmed word:eaten\n",
      "original word:writing----->stemmed word:write\n",
      "original word:writes----->stemmed word:write\n",
      "original word:programming----->stemmed word:program\n",
      "original word:programs----->stemmed word:program\n",
      "original word:programmed----->stemmed word:program\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(f\"original word:{word}----->stemmed word:{stemming.stem(word)}\")\n",
    "    # for some of the words i may not get the correct stemming.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a6846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"congratulations\")\n",
    "# the word generate has not the menaing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023aece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##stemming works for some of the words but for some of the words it may not get the correct word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d8dc42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47f4d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer=RegexpStemmer(\"ing$|s$|ed$|able$|ive$|ic$|ly$|es$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31a70842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem(\"eating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218eedeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ineat'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem(\"ineating\")\n",
    "## only of the last word removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac469e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SNOWBALL STEMMER\n",
    "## GIVE THE BETTER ACCURACY\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4e0ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowballstemmer=SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1afefc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original word:d----->stemmed word:d\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(f\"original word:{word}----->stemmed word:{stemming.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a76cca50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"fairly\"),stemming.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a8164b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballstemmer.stem(\"fairly\"),snowballstemmer.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbb1322f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('congratul', 'congratul')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballstemmer.stem(\"congratulations\"),stemming.stem(\"congratulations\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9e82924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'studi'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"studies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fd2560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af1caf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ece985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3c1d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff1b2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0127cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d002b056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a8913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b3d248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d2b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6a2ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31631728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d643daab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5136681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36215a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae196d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb484a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f64d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6b984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "requirements",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
